{"ast":null,"code":"import { fieldIntersection, hash, hasIntersection, isEmpty, keys, some } from '../../util';\nimport { requiresSelectionId } from '../selection';\nimport { AggregateNode } from './aggregate';\nimport { BinNode } from './bin';\nimport { OutputNode } from './dataflow';\nimport { FacetNode } from './facet';\nimport { FilterNode } from './filter';\nimport { ParseNode } from './formatparse';\nimport { IdentifierNode } from './identifier';\nimport { BottomUpOptimizer, isDataSourceNode, Optimizer, TopDownOptimizer } from './optimizer';\nimport { SourceNode } from './source';\nimport { TimeUnitNode } from './timeunit';\n/**\n * Merge identical nodes at forks by comparing hashes.\n *\n * Does not need to iterate from leaves so we implement this with recursion as it's a bit simpler.\n */\n\nexport class MergeIdenticalNodes extends TopDownOptimizer {\n  mergeNodes(parent, nodes) {\n    const mergedNode = nodes.shift();\n\n    for (const node of nodes) {\n      parent.removeChild(node);\n      node.parent = mergedNode;\n      node.remove();\n    }\n  }\n\n  run(node) {\n    const hashes = node.children.map(x => x.hash());\n    const buckets = {};\n\n    for (let i = 0; i < hashes.length; i++) {\n      if (buckets[hashes[i]] === undefined) {\n        buckets[hashes[i]] = [node.children[i]];\n      } else {\n        buckets[hashes[i]].push(node.children[i]);\n      }\n    }\n\n    for (const k of keys(buckets)) {\n      if (buckets[k].length > 1) {\n        this.setModified();\n        this.mergeNodes(node, buckets[k]);\n      }\n    }\n  }\n\n}\n/**\n * Optimizer that removes identifier nodes that are not needed for selections.\n */\n\nexport class RemoveUnnecessaryIdentifierNodes extends TopDownOptimizer {\n  constructor(model) {\n    super();\n    this.requiresSelectionId = model && requiresSelectionId(model);\n  }\n\n  run(node) {\n    if (node instanceof IdentifierNode) {\n      // Only preserve IdentifierNodes if we have default discrete selections\n      // in our model tree, and if the nodes come after tuple producing nodes.\n      if (!(this.requiresSelectionId && (isDataSourceNode(node.parent) || node.parent instanceof AggregateNode || node.parent instanceof ParseNode))) {\n        this.setModified();\n        node.remove();\n      }\n    }\n  }\n\n}\n/**\n * Removes duplicate time unit nodes (as determined by the name of the output field) that may be generated due to\n * selections projected over time units. Only keeps the first time unit in any branch.\n *\n * This optimizer is a custom top down optimizer that keep track of produced fields in a branch.\n */\n\nexport class RemoveDuplicateTimeUnits extends Optimizer {\n  optimize(node) {\n    this.run(node, new Set());\n    return this.modifiedFlag;\n  }\n\n  run(node, timeUnitFields) {\n    let producedFields = new Set();\n\n    if (node instanceof TimeUnitNode) {\n      producedFields = node.producedFields();\n\n      if (hasIntersection(producedFields, timeUnitFields)) {\n        this.setModified();\n        node.removeFormulas(timeUnitFields);\n\n        if (node.producedFields.length === 0) {\n          node.remove();\n        }\n      }\n    }\n\n    for (const child of node.children) {\n      this.run(child, new Set([...timeUnitFields, ...producedFields]));\n    }\n  }\n\n}\n/**\n * Remove output nodes that are not required.\n */\n\nexport class RemoveUnnecessaryOutputNodes extends TopDownOptimizer {\n  constructor() {\n    super();\n  }\n\n  run(node) {\n    if (node instanceof OutputNode && !node.isRequired()) {\n      this.setModified();\n      node.remove();\n    }\n  }\n\n}\n/**\n * Move parse nodes up to forks and merges them if possible.\n */\n\nexport class MoveParseUp extends BottomUpOptimizer {\n  run(node) {\n    if (isDataSourceNode(node)) {\n      return;\n    }\n\n    if (node.numChildren() > 1) {\n      // Don't move parse further up but continue with parent.\n      return;\n    }\n\n    for (const child of node.children) {\n      if (child instanceof ParseNode) {\n        if (node instanceof ParseNode) {\n          this.setModified();\n          node.merge(child);\n        } else {\n          // Don't swap with nodes that produce something that the parse node depends on (e.g. lookup).\n          if (fieldIntersection(node.producedFields(), child.dependentFields())) {\n            continue;\n          }\n\n          this.setModified();\n          child.swapWithParent();\n        }\n      }\n    }\n\n    return;\n  }\n\n}\n/**\n * Inserts an intermediate ParseNode containing all non-conflicting parse fields and removes the empty ParseNodes.\n *\n * We assume that dependent paths that do not have a parse node can be just merged.\n */\n\nexport class MergeParse extends BottomUpOptimizer {\n  run(node) {\n    const originalChildren = [...node.children];\n    const parseChildren = node.children.filter(child => child instanceof ParseNode);\n\n    if (node.numChildren() > 1 && parseChildren.length >= 1) {\n      const commonParse = {};\n      const conflictingParse = new Set();\n\n      for (const parseNode of parseChildren) {\n        const parse = parseNode.parse;\n\n        for (const k of keys(parse)) {\n          if (!(k in commonParse)) {\n            commonParse[k] = parse[k];\n          } else if (commonParse[k] !== parse[k]) {\n            conflictingParse.add(k);\n          }\n        }\n      }\n\n      for (const field of conflictingParse) {\n        delete commonParse[field];\n      }\n\n      if (!isEmpty(commonParse)) {\n        this.setModified();\n        const mergedParseNode = new ParseNode(node, commonParse);\n\n        for (const childNode of originalChildren) {\n          if (childNode instanceof ParseNode) {\n            for (const key of keys(commonParse)) {\n              delete childNode.parse[key];\n            }\n          }\n\n          node.removeChild(childNode);\n          childNode.parent = mergedParseNode; // remove empty parse nodes\n\n          if (childNode instanceof ParseNode && keys(childNode.parse).length === 0) {\n            childNode.remove();\n          }\n        }\n      }\n    }\n  }\n\n}\n/**\n * Repeatedly remove leaf nodes that are not output or facet nodes.\n * The reason is that we don't need subtrees that don't have any output nodes.\n * Facet nodes are needed for the row or column domains.\n */\n\nexport class RemoveUnusedSubtrees extends BottomUpOptimizer {\n  run(node) {\n    if (node instanceof OutputNode || node.numChildren() > 0 || node instanceof FacetNode) {// no need to continue with parent because it is output node or will have children (there was a fork)\n    } else if (node instanceof SourceNode) {// ignore empty unused sources as they will be removed in optimizationDataflowHelper\n    } else {\n      this.setModified();\n      node.remove();\n    }\n  }\n\n}\n/**\n * Merge adjacent time unit nodes.\n */\n\nexport class MergeTimeUnits extends BottomUpOptimizer {\n  run(node) {\n    const timeUnitChildren = node.children.filter(x => x instanceof TimeUnitNode);\n    const combination = timeUnitChildren.pop();\n\n    for (const timeUnit of timeUnitChildren) {\n      this.setModified();\n      combination.merge(timeUnit);\n    }\n  }\n\n}\nexport class MergeAggregates extends BottomUpOptimizer {\n  run(node) {\n    const aggChildren = node.children.filter(child => child instanceof AggregateNode); // Object which we'll use to map the fields which an aggregate is grouped by to\n    // the set of aggregates with that grouping. This is useful as only aggregates\n    // with the same group by can be merged\n\n    const groupedAggregates = {}; // Build groupedAggregates\n\n    for (const agg of aggChildren) {\n      const groupBys = hash(agg.groupBy);\n\n      if (!(groupBys in groupedAggregates)) {\n        groupedAggregates[groupBys] = [];\n      }\n\n      groupedAggregates[groupBys].push(agg);\n    } // Merge aggregateNodes with same key in groupedAggregates\n\n\n    for (const group of keys(groupedAggregates)) {\n      const mergeableAggs = groupedAggregates[group];\n\n      if (mergeableAggs.length > 1) {\n        const mergedAggs = mergeableAggs.pop();\n\n        for (const agg of mergeableAggs) {\n          if (mergedAggs.merge(agg)) {\n            node.removeChild(agg);\n            agg.parent = mergedAggs;\n            agg.remove();\n            this.setModified();\n          }\n        }\n      }\n    }\n  }\n\n}\n/**\n * Merge bin nodes and move them up through forks. Stop at filters, parse, identifier as we want them to stay before the bin node.\n */\n\nexport class MergeBins extends BottomUpOptimizer {\n  constructor(model) {\n    super();\n    this.model = model;\n  }\n\n  run(node) {\n    const moveBinsUp = !(isDataSourceNode(node) || node instanceof FilterNode || node instanceof ParseNode || node instanceof IdentifierNode);\n    const promotableBins = [];\n    const remainingBins = [];\n\n    for (const child of node.children) {\n      if (child instanceof BinNode) {\n        if (moveBinsUp && !fieldIntersection(node.producedFields(), child.dependentFields())) {\n          promotableBins.push(child);\n        } else {\n          remainingBins.push(child);\n        }\n      }\n    }\n\n    if (promotableBins.length > 0) {\n      const promotedBin = promotableBins.pop();\n\n      for (const bin of promotableBins) {\n        promotedBin.merge(bin, this.model.renameSignal.bind(this.model));\n      }\n\n      this.setModified();\n\n      if (node instanceof BinNode) {\n        node.merge(promotedBin, this.model.renameSignal.bind(this.model));\n      } else {\n        promotedBin.swapWithParent();\n      }\n    }\n\n    if (remainingBins.length > 1) {\n      const remainingBin = remainingBins.pop();\n\n      for (const bin of remainingBins) {\n        remainingBin.merge(bin, this.model.renameSignal.bind(this.model));\n      }\n\n      this.setModified();\n    }\n  }\n\n}\n/**\n * This optimizer takes output nodes that are at a fork and moves them before the fork.\n *\n * The algorithm iterates over the children and tries to find the last output node in a chain of output nodes.\n * It then moves all output nodes before that main output node. All other children (and the children of the output nodes)\n * are inserted after the main output node.\n */\n\nexport class MergeOutputs extends BottomUpOptimizer {\n  run(node) {\n    const children = [...node.children];\n    const hasOutputChild = some(children, child => child instanceof OutputNode);\n\n    if (!hasOutputChild || node.numChildren() <= 1) {\n      return;\n    }\n\n    const otherChildren = []; // The output node we will connect all other nodes to.\n    // Output nodes will be added before the new node, other nodes after.\n\n    let mainOutput;\n\n    for (const child of children) {\n      if (child instanceof OutputNode) {\n        let lastOutput = child;\n\n        while (lastOutput.numChildren() === 1) {\n          const [theChild] = lastOutput.children;\n\n          if (theChild instanceof OutputNode) {\n            lastOutput = theChild;\n          } else {\n            break;\n          }\n        }\n\n        otherChildren.push(...lastOutput.children);\n\n        if (mainOutput) {\n          // Move the output nodes before the mainOutput. We do this by setting\n          // the parent of the first not to the parent of the main output and\n          // the main output's parent to the last output.\n          // note: the child is the first output\n          node.removeChild(child);\n          child.parent = mainOutput.parent;\n          mainOutput.parent.removeChild(mainOutput);\n          mainOutput.parent = lastOutput;\n          this.setModified();\n        } else {\n          mainOutput = lastOutput;\n        }\n      } else {\n        otherChildren.push(child);\n      }\n    }\n\n    if (otherChildren.length) {\n      this.setModified();\n\n      for (const child of otherChildren) {\n        child.parent.removeChild(child);\n        child.parent = mainOutput;\n      }\n    }\n  }\n\n}","map":{"version":3,"mappings":"AACA,SAAcA,iBAAd,EAAiCC,IAAjC,EAAuCC,eAAvC,EAAwDC,OAAxD,EAAiEC,IAAjE,EAAuEC,IAAvE,QAAkF,YAAlF;AAEA,SAAQC,mBAAR,QAAkC,cAAlC;AACA,SAAQC,aAAR,QAA4B,aAA5B;AACA,SAAQC,OAAR,QAAsB,OAAtB;AACA,SAAsBC,UAAtB,QAAuC,YAAvC;AACA,SAAQC,SAAR,QAAwB,SAAxB;AACA,SAAQC,UAAR,QAAyB,UAAzB;AACA,SAAQC,SAAR,QAAwB,eAAxB;AACA,SAAQC,cAAR,QAA6B,cAA7B;AACA,SAAQC,iBAAR,EAA2BC,gBAA3B,EAA6CC,SAA7C,EAAwDC,gBAAxD,QAA+E,aAA/E;AACA,SAAQC,UAAR,QAAyB,UAAzB;AACA,SAAQC,YAAR,QAA2B,YAA3B;AAEA;;;;;;AAKA,OAAM,MAAOC,mBAAP,SAAmCH,gBAAnC,CAAmD;EAChDI,UAAU,CAACC,MAAD,EAAuBC,KAAvB,EAA4C;IAC3D,MAAMC,UAAU,GAAGD,KAAK,CAACE,KAAN,EAAnB;;IACA,KAAK,MAAMC,IAAX,IAAmBH,KAAnB,EAA0B;MACxBD,MAAM,CAACK,WAAP,CAAmBD,IAAnB;MACAA,IAAI,CAACJ,MAAL,GAAcE,UAAd;MACAE,IAAI,CAACE,MAAL;IACD;EACF;;EAEMC,GAAG,CAACH,IAAD,EAAmB;IAC3B,MAAMI,MAAM,GAAGJ,IAAI,CAACK,QAAL,CAAcC,GAAd,CAAkBC,CAAC,IAAIA,CAAC,CAAChC,IAAF,EAAvB,CAAf;IACA,MAAMiC,OAAO,GAA4B,EAAzC;;IAEA,KAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,MAAM,CAACM,MAA3B,EAAmCD,CAAC,EAApC,EAAwC;MACtC,IAAID,OAAO,CAACJ,MAAM,CAACK,CAAD,CAAP,CAAP,KAAuBE,SAA3B,EAAsC;QACpCH,OAAO,CAACJ,MAAM,CAACK,CAAD,CAAP,CAAP,GAAqB,CAACT,IAAI,CAACK,QAAL,CAAcI,CAAd,CAAD,CAArB;MACD,CAFD,MAEO;QACLD,OAAO,CAACJ,MAAM,CAACK,CAAD,CAAP,CAAP,CAAmBG,IAAnB,CAAwBZ,IAAI,CAACK,QAAL,CAAcI,CAAd,CAAxB;MACD;IACF;;IAED,KAAK,MAAMI,CAAX,IAAgBnC,IAAI,CAAC8B,OAAD,CAApB,EAA+B;MAC7B,IAAIA,OAAO,CAACK,CAAD,CAAP,CAAWH,MAAX,GAAoB,CAAxB,EAA2B;QACzB,KAAKI,WAAL;QACA,KAAKnB,UAAL,CAAgBK,IAAhB,EAAsBQ,OAAO,CAACK,CAAD,CAA7B;MACD;IACF;EACF;;AA5BsD;AA+BzD;;;;AAGA,OAAM,MAAOE,gCAAP,SAAgDxB,gBAAhD,CAAgE;EAGpEyB,YAAYC,KAAZ,EAAwB;IACtB;IACA,KAAKrC,mBAAL,GAA2BqC,KAAK,IAAIrC,mBAAmB,CAACqC,KAAD,CAAvD;EACD;;EAEMd,GAAG,CAACH,IAAD,EAAmB;IAC3B,IAAIA,IAAI,YAAYb,cAApB,EAAoC;MAClC;MACA;MACA,IACE,EACE,KAAKP,mBAAL,KACCS,gBAAgB,CAACW,IAAI,CAACJ,MAAN,CAAhB,IAAiCI,IAAI,CAACJ,MAAL,YAAuBf,aAAxD,IAAyEmB,IAAI,CAACJ,MAAL,YAAuBV,SADjG,CADF,CADF,EAKE;QACA,KAAK4B,WAAL;QACAd,IAAI,CAACE,MAAL;MACD;IACF;EACF;;AAtBmE;AAyBtE;;;;;;;AAMA,OAAM,MAAOgB,wBAAP,SAAwC5B,SAAxC,CAAiD;EAC9C6B,QAAQ,CAACnB,IAAD,EAAmB;IAChC,KAAKG,GAAL,CAASH,IAAT,EAAe,IAAIoB,GAAJ,EAAf;IAEA,OAAO,KAAKC,YAAZ;EACD;;EAEMlB,GAAG,CAACH,IAAD,EAAqBsB,cAArB,EAAgD;IACxD,IAAIC,cAAc,GAAG,IAAIH,GAAJ,EAArB;;IAEA,IAAIpB,IAAI,YAAYP,YAApB,EAAkC;MAChC8B,cAAc,GAAGvB,IAAI,CAACuB,cAAL,EAAjB;;MACA,IAAI/C,eAAe,CAAC+C,cAAD,EAAiBD,cAAjB,CAAnB,EAAqD;QACnD,KAAKR,WAAL;QACAd,IAAI,CAACwB,cAAL,CAAoBF,cAApB;;QACA,IAAItB,IAAI,CAACuB,cAAL,CAAoBb,MAApB,KAA+B,CAAnC,EAAsC;UACpCV,IAAI,CAACE,MAAL;QACD;MACF;IACF;;IAED,KAAK,MAAMuB,KAAX,IAAoBzB,IAAI,CAACK,QAAzB,EAAmC;MACjC,KAAKF,GAAL,CAASsB,KAAT,EAAgB,IAAIL,GAAJ,CAAQ,CAAC,GAAGE,cAAJ,EAAoB,GAAGC,cAAvB,CAAR,CAAhB;IACD;EACF;;AAxBoD;AA2BvD;;;;AAGA,OAAM,MAAOG,4BAAP,SAA4CnC,gBAA5C,CAA4D;EAChEyB;IACE;EACD;;EAEMb,GAAG,CAACH,IAAD,EAAmB;IAC3B,IAAIA,IAAI,YAAYjB,UAAhB,IAA8B,CAACiB,IAAI,CAAC2B,UAAL,EAAnC,EAAsD;MACpD,KAAKb,WAAL;MACAd,IAAI,CAACE,MAAL;IACD;EACF;;AAV+D;AAalE;;;;AAGA,OAAM,MAAO0B,WAAP,SAA2BxC,iBAA3B,CAA4C;EACzCe,GAAG,CAACH,IAAD,EAAmB;IAC3B,IAAIX,gBAAgB,CAACW,IAAD,CAApB,EAA4B;MAC1B;IACD;;IAED,IAAIA,IAAI,CAAC6B,WAAL,KAAqB,CAAzB,EAA4B;MAC1B;MACA;IACD;;IAED,KAAK,MAAMJ,KAAX,IAAoBzB,IAAI,CAACK,QAAzB,EAAmC;MACjC,IAAIoB,KAAK,YAAYvC,SAArB,EAAgC;QAC9B,IAAIc,IAAI,YAAYd,SAApB,EAA+B;UAC7B,KAAK4B,WAAL;UACAd,IAAI,CAAC8B,KAAL,CAAWL,KAAX;QACD,CAHD,MAGO;UACL;UACA,IAAInD,iBAAiB,CAAC0B,IAAI,CAACuB,cAAL,EAAD,EAAwBE,KAAK,CAACM,eAAN,EAAxB,CAArB,EAAuE;YACrE;UACD;;UACD,KAAKjB,WAAL;UACAW,KAAK,CAACO,cAAN;QACD;MACF;IACF;;IAED;EACD;;AA5B+C;AA+BlD;;;;;;AAKA,OAAM,MAAOC,UAAP,SAA0B7C,iBAA1B,CAA2C;EACxCe,GAAG,CAACH,IAAD,EAAmB;IAC3B,MAAMkC,gBAAgB,GAAG,CAAC,GAAGlC,IAAI,CAACK,QAAT,CAAzB;IACA,MAAM8B,aAAa,GAAGnC,IAAI,CAACK,QAAL,CAAc+B,MAAd,CAAsBX,KAAD,IAA+BA,KAAK,YAAYvC,SAArE,CAAtB;;IAEA,IAAIc,IAAI,CAAC6B,WAAL,KAAqB,CAArB,IAA0BM,aAAa,CAACzB,MAAd,IAAwB,CAAtD,EAAyD;MACvD,MAAM2B,WAAW,GAAU,EAA3B;MACA,MAAMC,gBAAgB,GAAG,IAAIlB,GAAJ,EAAzB;;MACA,KAAK,MAAMmB,SAAX,IAAwBJ,aAAxB,EAAuC;QACrC,MAAMK,KAAK,GAAGD,SAAS,CAACC,KAAxB;;QACA,KAAK,MAAM3B,CAAX,IAAgBnC,IAAI,CAAC8D,KAAD,CAApB,EAA6B;UAC3B,IAAI,EAAE3B,CAAC,IAAIwB,WAAP,CAAJ,EAAyB;YACvBA,WAAW,CAACxB,CAAD,CAAX,GAAiB2B,KAAK,CAAC3B,CAAD,CAAtB;UACD,CAFD,MAEO,IAAIwB,WAAW,CAACxB,CAAD,CAAX,KAAmB2B,KAAK,CAAC3B,CAAD,CAA5B,EAAiC;YACtCyB,gBAAgB,CAACG,GAAjB,CAAqB5B,CAArB;UACD;QACF;MACF;;MAED,KAAK,MAAM6B,KAAX,IAAoBJ,gBAApB,EAAsC;QACpC,OAAOD,WAAW,CAACK,KAAD,CAAlB;MACD;;MAED,IAAI,CAACjE,OAAO,CAAC4D,WAAD,CAAZ,EAA2B;QACzB,KAAKvB,WAAL;QACA,MAAM6B,eAAe,GAAG,IAAIzD,SAAJ,CAAcc,IAAd,EAAoBqC,WAApB,CAAxB;;QACA,KAAK,MAAMO,SAAX,IAAwBV,gBAAxB,EAA0C;UACxC,IAAIU,SAAS,YAAY1D,SAAzB,EAAoC;YAClC,KAAK,MAAM2D,GAAX,IAAkBnE,IAAI,CAAC2D,WAAD,CAAtB,EAAqC;cACnC,OAAOO,SAAS,CAACJ,KAAV,CAAgBK,GAAhB,CAAP;YACD;UACF;;UAED7C,IAAI,CAACC,WAAL,CAAiB2C,SAAjB;UACAA,SAAS,CAAChD,MAAV,GAAmB+C,eAAnB,CARwC,CAUxC;;UACA,IAAIC,SAAS,YAAY1D,SAArB,IAAkCR,IAAI,CAACkE,SAAS,CAACJ,KAAX,CAAJ,CAAsB9B,MAAtB,KAAiC,CAAvE,EAA0E;YACxEkC,SAAS,CAAC1C,MAAV;UACD;QACF;MACF;IACF;EACF;;AA3C8C;AA8CjD;;;;;;AAKA,OAAM,MAAO4C,oBAAP,SAAoC1D,iBAApC,CAAqD;EAClDe,GAAG,CAACH,IAAD,EAAmB;IAC3B,IAAIA,IAAI,YAAYjB,UAAhB,IAA8BiB,IAAI,CAAC6B,WAAL,KAAqB,CAAnD,IAAwD7B,IAAI,YAAYhB,SAA5E,EAAuF,CACrF;IACD,CAFD,MAEO,IAAIgB,IAAI,YAAYR,UAApB,EAAgC,CACrC;IACD,CAFM,MAEA;MACL,KAAKsB,WAAL;MACAd,IAAI,CAACE,MAAL;IACD;EACF;;AAVwD;AAa3D;;;;AAGA,OAAM,MAAO6C,cAAP,SAA8B3D,iBAA9B,CAA+C;EAC5Ce,GAAG,CAACH,IAAD,EAAmB;IAC3B,MAAMgD,gBAAgB,GAAGhD,IAAI,CAACK,QAAL,CAAc+B,MAAd,CAAsB7B,CAAD,IAA0BA,CAAC,YAAYd,YAA5D,CAAzB;IACA,MAAMwD,WAAW,GAAGD,gBAAgB,CAACE,GAAjB,EAApB;;IACA,KAAK,MAAMC,QAAX,IAAuBH,gBAAvB,EAAyC;MACvC,KAAKlC,WAAL;MACAmC,WAAW,CAACnB,KAAZ,CAAkBqB,QAAlB;IACD;EACF;;AARkD;AAWrD,OAAM,MAAOC,eAAP,SAA+BhE,iBAA/B,CAAgD;EAC7Ce,GAAG,CAACH,IAAD,EAAmB;IAC3B,MAAMqD,WAAW,GAAGrD,IAAI,CAACK,QAAL,CAAc+B,MAAd,CAAsBX,KAAD,IAAmCA,KAAK,YAAY5C,aAAzE,CAApB,CAD2B,CAG3B;IACA;IACA;;IACA,MAAMyE,iBAAiB,GAA0B,EAAjD,CAN2B,CAQ3B;;IACA,KAAK,MAAMC,GAAX,IAAkBF,WAAlB,EAA+B;MAC7B,MAAMG,QAAQ,GAAGjF,IAAI,CAACgF,GAAG,CAACE,OAAL,CAArB;;MACA,IAAI,EAAED,QAAQ,IAAIF,iBAAd,CAAJ,EAAsC;QACpCA,iBAAiB,CAACE,QAAD,CAAjB,GAA8B,EAA9B;MACD;;MACDF,iBAAiB,CAACE,QAAD,CAAjB,CAA4B5C,IAA5B,CAAiC2C,GAAjC;IACD,CAf0B,CAiB3B;;;IACA,KAAK,MAAMG,KAAX,IAAoBhF,IAAI,CAAC4E,iBAAD,CAAxB,EAA6C;MAC3C,MAAMK,aAAa,GAAGL,iBAAiB,CAACI,KAAD,CAAvC;;MACA,IAAIC,aAAa,CAACjD,MAAd,GAAuB,CAA3B,EAA8B;QAC5B,MAAMkD,UAAU,GAAGD,aAAa,CAACT,GAAd,EAAnB;;QACA,KAAK,MAAMK,GAAX,IAAkBI,aAAlB,EAAiC;UAC/B,IAAIC,UAAU,CAAC9B,KAAX,CAAiByB,GAAjB,CAAJ,EAA2B;YACzBvD,IAAI,CAACC,WAAL,CAAiBsD,GAAjB;YACAA,GAAG,CAAC3D,MAAJ,GAAagE,UAAb;YACAL,GAAG,CAACrD,MAAJ;YAEA,KAAKY,WAAL;UACD;QACF;MACF;IACF;EACF;;AAlCmD;AAqCtD;;;;AAGA,OAAM,MAAO+C,SAAP,SAAyBzE,iBAAzB,CAA0C;EAC9C4B,YAAoBC,KAApB,EAAgC;IAC9B;IADkB;EAEnB;;EAEMd,GAAG,CAACH,IAAD,EAAmB;IAC3B,MAAM8D,UAAU,GAAG,EACjBzE,gBAAgB,CAACW,IAAD,CAAhB,IACAA,IAAI,YAAYf,UADhB,IAEAe,IAAI,YAAYd,SAFhB,IAGAc,IAAI,YAAYb,cAJC,CAAnB;IAOA,MAAM4E,cAAc,GAAc,EAAlC;IACA,MAAMC,aAAa,GAAc,EAAjC;;IAEA,KAAK,MAAMvC,KAAX,IAAoBzB,IAAI,CAACK,QAAzB,EAAmC;MACjC,IAAIoB,KAAK,YAAY3C,OAArB,EAA8B;QAC5B,IAAIgF,UAAU,IAAI,CAACxF,iBAAiB,CAAC0B,IAAI,CAACuB,cAAL,EAAD,EAAwBE,KAAK,CAACM,eAAN,EAAxB,CAApC,EAAsF;UACpFgC,cAAc,CAACnD,IAAf,CAAoBa,KAApB;QACD,CAFD,MAEO;UACLuC,aAAa,CAACpD,IAAd,CAAmBa,KAAnB;QACD;MACF;IACF;;IAED,IAAIsC,cAAc,CAACrD,MAAf,GAAwB,CAA5B,EAA+B;MAC7B,MAAMuD,WAAW,GAAGF,cAAc,CAACb,GAAf,EAApB;;MACA,KAAK,MAAMgB,GAAX,IAAkBH,cAAlB,EAAkC;QAChCE,WAAW,CAACnC,KAAZ,CAAkBoC,GAAlB,EAAuB,KAAKjD,KAAL,CAAWkD,YAAX,CAAwBC,IAAxB,CAA6B,KAAKnD,KAAlC,CAAvB;MACD;;MACD,KAAKH,WAAL;;MACA,IAAId,IAAI,YAAYlB,OAApB,EAA6B;QAC3BkB,IAAI,CAAC8B,KAAL,CAAWmC,WAAX,EAAwB,KAAKhD,KAAL,CAAWkD,YAAX,CAAwBC,IAAxB,CAA6B,KAAKnD,KAAlC,CAAxB;MACD,CAFD,MAEO;QACLgD,WAAW,CAACjC,cAAZ;MACD;IACF;;IACD,IAAIgC,aAAa,CAACtD,MAAd,GAAuB,CAA3B,EAA8B;MAC5B,MAAM2D,YAAY,GAAGL,aAAa,CAACd,GAAd,EAArB;;MACA,KAAK,MAAMgB,GAAX,IAAkBF,aAAlB,EAAiC;QAC/BK,YAAY,CAACvC,KAAb,CAAmBoC,GAAnB,EAAwB,KAAKjD,KAAL,CAAWkD,YAAX,CAAwBC,IAAxB,CAA6B,KAAKnD,KAAlC,CAAxB;MACD;;MACD,KAAKH,WAAL;IACD;EACF;;AA7C6C;AAgDhD;;;;;;;;AAOA,OAAM,MAAOwD,YAAP,SAA4BlF,iBAA5B,CAA6C;EAC1Ce,GAAG,CAACH,IAAD,EAAmB;IAC3B,MAAMK,QAAQ,GAAG,CAAC,GAAGL,IAAI,CAACK,QAAT,CAAjB;IACA,MAAMkE,cAAc,GAAG5F,IAAI,CAAC0B,QAAD,EAAWoB,KAAK,IAAIA,KAAK,YAAY1C,UAArC,CAA3B;;IAEA,IAAI,CAACwF,cAAD,IAAmBvE,IAAI,CAAC6B,WAAL,MAAsB,CAA7C,EAAgD;MAC9C;IACD;;IAED,MAAM2C,aAAa,GAAmB,EAAtC,CAR2B,CAU3B;IACA;;IACA,IAAIC,UAAJ;;IAEA,KAAK,MAAMhD,KAAX,IAAoBpB,QAApB,EAA8B;MAC5B,IAAIoB,KAAK,YAAY1C,UAArB,EAAiC;QAC/B,IAAI2F,UAAU,GAAGjD,KAAjB;;QAEA,OAAOiD,UAAU,CAAC7C,WAAX,OAA6B,CAApC,EAAuC;UACrC,MAAM,CAAC8C,QAAD,IAAaD,UAAU,CAACrE,QAA9B;;UACA,IAAIsE,QAAQ,YAAY5F,UAAxB,EAAoC;YAClC2F,UAAU,GAAGC,QAAb;UACD,CAFD,MAEO;YACL;UACD;QACF;;QAEDH,aAAa,CAAC5D,IAAd,CAAmB,GAAG8D,UAAU,CAACrE,QAAjC;;QAEA,IAAIoE,UAAJ,EAAgB;UACd;UACA;UACA;UAEA;UACAzE,IAAI,CAACC,WAAL,CAAiBwB,KAAjB;UACAA,KAAK,CAAC7B,MAAN,GAAe6E,UAAU,CAAC7E,MAA1B;UAEA6E,UAAU,CAAC7E,MAAX,CAAkBK,WAAlB,CAA8BwE,UAA9B;UACAA,UAAU,CAAC7E,MAAX,GAAoB8E,UAApB;UAEA,KAAK5D,WAAL;QACD,CAbD,MAaO;UACL2D,UAAU,GAAGC,UAAb;QACD;MACF,CA9BD,MA8BO;QACLF,aAAa,CAAC5D,IAAd,CAAmBa,KAAnB;MACD;IACF;;IAED,IAAI+C,aAAa,CAAC9D,MAAlB,EAA0B;MACxB,KAAKI,WAAL;;MACA,KAAK,MAAMW,KAAX,IAAoB+C,aAApB,EAAmC;QACjC/C,KAAK,CAAC7B,MAAN,CAAaK,WAAb,CAAyBwB,KAAzB;QACAA,KAAK,CAAC7B,MAAN,GAAe6E,UAAf;MACD;IACF;EACF;;AA1DgD","names":["fieldIntersection","hash","hasIntersection","isEmpty","keys","some","requiresSelectionId","AggregateNode","BinNode","OutputNode","FacetNode","FilterNode","ParseNode","IdentifierNode","BottomUpOptimizer","isDataSourceNode","Optimizer","TopDownOptimizer","SourceNode","TimeUnitNode","MergeIdenticalNodes","mergeNodes","parent","nodes","mergedNode","shift","node","removeChild","remove","run","hashes","children","map","x","buckets","i","length","undefined","push","k","setModified","RemoveUnnecessaryIdentifierNodes","constructor","model","RemoveDuplicateTimeUnits","optimize","Set","modifiedFlag","timeUnitFields","producedFields","removeFormulas","child","RemoveUnnecessaryOutputNodes","isRequired","MoveParseUp","numChildren","merge","dependentFields","swapWithParent","MergeParse","originalChildren","parseChildren","filter","commonParse","conflictingParse","parseNode","parse","add","field","mergedParseNode","childNode","key","RemoveUnusedSubtrees","MergeTimeUnits","timeUnitChildren","combination","pop","timeUnit","MergeAggregates","aggChildren","groupedAggregates","agg","groupBys","groupBy","group","mergeableAggs","mergedAggs","MergeBins","moveBinsUp","promotableBins","remainingBins","promotedBin","bin","renameSignal","bind","remainingBin","MergeOutputs","hasOutputChild","otherChildren","mainOutput","lastOutput","theChild"],"sources":["/Users/darcyroche/Documents/cathracha is tíreolaíocht/public life observations/plo-viz-app/node_modules/vega-lite/src/compile/data/optimizers.ts"],"sourcesContent":["import {Parse} from '../../data';\nimport {Dict, fieldIntersection, hash, hasIntersection, isEmpty, keys, some} from '../../util';\nimport {Model} from '../model';\nimport {requiresSelectionId} from '../selection';\nimport {AggregateNode} from './aggregate';\nimport {BinNode} from './bin';\nimport {DataFlowNode, OutputNode} from './dataflow';\nimport {FacetNode} from './facet';\nimport {FilterNode} from './filter';\nimport {ParseNode} from './formatparse';\nimport {IdentifierNode} from './identifier';\nimport {BottomUpOptimizer, isDataSourceNode, Optimizer, TopDownOptimizer} from './optimizer';\nimport {SourceNode} from './source';\nimport {TimeUnitNode} from './timeunit';\n\n/**\n * Merge identical nodes at forks by comparing hashes.\n *\n * Does not need to iterate from leaves so we implement this with recursion as it's a bit simpler.\n */\nexport class MergeIdenticalNodes extends TopDownOptimizer {\n  public mergeNodes(parent: DataFlowNode, nodes: DataFlowNode[]) {\n    const mergedNode = nodes.shift();\n    for (const node of nodes) {\n      parent.removeChild(node);\n      node.parent = mergedNode;\n      node.remove();\n    }\n  }\n\n  public run(node: DataFlowNode) {\n    const hashes = node.children.map(x => x.hash());\n    const buckets: {hash?: DataFlowNode[]} = {};\n\n    for (let i = 0; i < hashes.length; i++) {\n      if (buckets[hashes[i]] === undefined) {\n        buckets[hashes[i]] = [node.children[i]];\n      } else {\n        buckets[hashes[i]].push(node.children[i]);\n      }\n    }\n\n    for (const k of keys(buckets)) {\n      if (buckets[k].length > 1) {\n        this.setModified();\n        this.mergeNodes(node, buckets[k]);\n      }\n    }\n  }\n}\n\n/**\n * Optimizer that removes identifier nodes that are not needed for selections.\n */\nexport class RemoveUnnecessaryIdentifierNodes extends TopDownOptimizer {\n  private requiresSelectionId: boolean;\n\n  constructor(model: Model) {\n    super();\n    this.requiresSelectionId = model && requiresSelectionId(model);\n  }\n\n  public run(node: DataFlowNode) {\n    if (node instanceof IdentifierNode) {\n      // Only preserve IdentifierNodes if we have default discrete selections\n      // in our model tree, and if the nodes come after tuple producing nodes.\n      if (\n        !(\n          this.requiresSelectionId &&\n          (isDataSourceNode(node.parent) || node.parent instanceof AggregateNode || node.parent instanceof ParseNode)\n        )\n      ) {\n        this.setModified();\n        node.remove();\n      }\n    }\n  }\n}\n\n/**\n * Removes duplicate time unit nodes (as determined by the name of the output field) that may be generated due to\n * selections projected over time units. Only keeps the first time unit in any branch.\n *\n * This optimizer is a custom top down optimizer that keep track of produced fields in a branch.\n */\nexport class RemoveDuplicateTimeUnits extends Optimizer {\n  public optimize(node: DataFlowNode): boolean {\n    this.run(node, new Set());\n\n    return this.modifiedFlag;\n  }\n\n  public run(node: DataFlowNode, timeUnitFields: Set<string>) {\n    let producedFields = new Set<string>();\n\n    if (node instanceof TimeUnitNode) {\n      producedFields = node.producedFields();\n      if (hasIntersection(producedFields, timeUnitFields)) {\n        this.setModified();\n        node.removeFormulas(timeUnitFields);\n        if (node.producedFields.length === 0) {\n          node.remove();\n        }\n      }\n    }\n\n    for (const child of node.children) {\n      this.run(child, new Set([...timeUnitFields, ...producedFields]));\n    }\n  }\n}\n\n/**\n * Remove output nodes that are not required.\n */\nexport class RemoveUnnecessaryOutputNodes extends TopDownOptimizer {\n  constructor() {\n    super();\n  }\n\n  public run(node: DataFlowNode) {\n    if (node instanceof OutputNode && !node.isRequired()) {\n      this.setModified();\n      node.remove();\n    }\n  }\n}\n\n/**\n * Move parse nodes up to forks and merges them if possible.\n */\nexport class MoveParseUp extends BottomUpOptimizer {\n  public run(node: DataFlowNode) {\n    if (isDataSourceNode(node)) {\n      return;\n    }\n\n    if (node.numChildren() > 1) {\n      // Don't move parse further up but continue with parent.\n      return;\n    }\n\n    for (const child of node.children) {\n      if (child instanceof ParseNode) {\n        if (node instanceof ParseNode) {\n          this.setModified();\n          node.merge(child);\n        } else {\n          // Don't swap with nodes that produce something that the parse node depends on (e.g. lookup).\n          if (fieldIntersection(node.producedFields(), child.dependentFields())) {\n            continue;\n          }\n          this.setModified();\n          child.swapWithParent();\n        }\n      }\n    }\n\n    return;\n  }\n}\n\n/**\n * Inserts an intermediate ParseNode containing all non-conflicting parse fields and removes the empty ParseNodes.\n *\n * We assume that dependent paths that do not have a parse node can be just merged.\n */\nexport class MergeParse extends BottomUpOptimizer {\n  public run(node: DataFlowNode) {\n    const originalChildren = [...node.children];\n    const parseChildren = node.children.filter((child): child is ParseNode => child instanceof ParseNode);\n\n    if (node.numChildren() > 1 && parseChildren.length >= 1) {\n      const commonParse: Parse = {};\n      const conflictingParse = new Set<string>();\n      for (const parseNode of parseChildren) {\n        const parse = parseNode.parse;\n        for (const k of keys(parse)) {\n          if (!(k in commonParse)) {\n            commonParse[k] = parse[k];\n          } else if (commonParse[k] !== parse[k]) {\n            conflictingParse.add(k);\n          }\n        }\n      }\n\n      for (const field of conflictingParse) {\n        delete commonParse[field];\n      }\n\n      if (!isEmpty(commonParse)) {\n        this.setModified();\n        const mergedParseNode = new ParseNode(node, commonParse);\n        for (const childNode of originalChildren) {\n          if (childNode instanceof ParseNode) {\n            for (const key of keys(commonParse)) {\n              delete childNode.parse[key];\n            }\n          }\n\n          node.removeChild(childNode);\n          childNode.parent = mergedParseNode;\n\n          // remove empty parse nodes\n          if (childNode instanceof ParseNode && keys(childNode.parse).length === 0) {\n            childNode.remove();\n          }\n        }\n      }\n    }\n  }\n}\n\n/**\n * Repeatedly remove leaf nodes that are not output or facet nodes.\n * The reason is that we don't need subtrees that don't have any output nodes.\n * Facet nodes are needed for the row or column domains.\n */\nexport class RemoveUnusedSubtrees extends BottomUpOptimizer {\n  public run(node: DataFlowNode) {\n    if (node instanceof OutputNode || node.numChildren() > 0 || node instanceof FacetNode) {\n      // no need to continue with parent because it is output node or will have children (there was a fork)\n    } else if (node instanceof SourceNode) {\n      // ignore empty unused sources as they will be removed in optimizationDataflowHelper\n    } else {\n      this.setModified();\n      node.remove();\n    }\n  }\n}\n\n/**\n * Merge adjacent time unit nodes.\n */\nexport class MergeTimeUnits extends BottomUpOptimizer {\n  public run(node: DataFlowNode) {\n    const timeUnitChildren = node.children.filter((x): x is TimeUnitNode => x instanceof TimeUnitNode);\n    const combination = timeUnitChildren.pop();\n    for (const timeUnit of timeUnitChildren) {\n      this.setModified();\n      combination.merge(timeUnit);\n    }\n  }\n}\n\nexport class MergeAggregates extends BottomUpOptimizer {\n  public run(node: DataFlowNode) {\n    const aggChildren = node.children.filter((child): child is AggregateNode => child instanceof AggregateNode);\n\n    // Object which we'll use to map the fields which an aggregate is grouped by to\n    // the set of aggregates with that grouping. This is useful as only aggregates\n    // with the same group by can be merged\n    const groupedAggregates: Dict<AggregateNode[]> = {};\n\n    // Build groupedAggregates\n    for (const agg of aggChildren) {\n      const groupBys = hash(agg.groupBy);\n      if (!(groupBys in groupedAggregates)) {\n        groupedAggregates[groupBys] = [];\n      }\n      groupedAggregates[groupBys].push(agg);\n    }\n\n    // Merge aggregateNodes with same key in groupedAggregates\n    for (const group of keys(groupedAggregates)) {\n      const mergeableAggs = groupedAggregates[group];\n      if (mergeableAggs.length > 1) {\n        const mergedAggs = mergeableAggs.pop();\n        for (const agg of mergeableAggs) {\n          if (mergedAggs.merge(agg)) {\n            node.removeChild(agg);\n            agg.parent = mergedAggs;\n            agg.remove();\n\n            this.setModified();\n          }\n        }\n      }\n    }\n  }\n}\n\n/**\n * Merge bin nodes and move them up through forks. Stop at filters, parse, identifier as we want them to stay before the bin node.\n */\nexport class MergeBins extends BottomUpOptimizer {\n  constructor(private model: Model) {\n    super();\n  }\n\n  public run(node: DataFlowNode) {\n    const moveBinsUp = !(\n      isDataSourceNode(node) ||\n      node instanceof FilterNode ||\n      node instanceof ParseNode ||\n      node instanceof IdentifierNode\n    );\n\n    const promotableBins: BinNode[] = [];\n    const remainingBins: BinNode[] = [];\n\n    for (const child of node.children) {\n      if (child instanceof BinNode) {\n        if (moveBinsUp && !fieldIntersection(node.producedFields(), child.dependentFields())) {\n          promotableBins.push(child);\n        } else {\n          remainingBins.push(child);\n        }\n      }\n    }\n\n    if (promotableBins.length > 0) {\n      const promotedBin = promotableBins.pop();\n      for (const bin of promotableBins) {\n        promotedBin.merge(bin, this.model.renameSignal.bind(this.model));\n      }\n      this.setModified();\n      if (node instanceof BinNode) {\n        node.merge(promotedBin, this.model.renameSignal.bind(this.model));\n      } else {\n        promotedBin.swapWithParent();\n      }\n    }\n    if (remainingBins.length > 1) {\n      const remainingBin = remainingBins.pop();\n      for (const bin of remainingBins) {\n        remainingBin.merge(bin, this.model.renameSignal.bind(this.model));\n      }\n      this.setModified();\n    }\n  }\n}\n\n/**\n * This optimizer takes output nodes that are at a fork and moves them before the fork.\n *\n * The algorithm iterates over the children and tries to find the last output node in a chain of output nodes.\n * It then moves all output nodes before that main output node. All other children (and the children of the output nodes)\n * are inserted after the main output node.\n */\nexport class MergeOutputs extends BottomUpOptimizer {\n  public run(node: DataFlowNode) {\n    const children = [...node.children];\n    const hasOutputChild = some(children, child => child instanceof OutputNode);\n\n    if (!hasOutputChild || node.numChildren() <= 1) {\n      return;\n    }\n\n    const otherChildren: DataFlowNode[] = [];\n\n    // The output node we will connect all other nodes to.\n    // Output nodes will be added before the new node, other nodes after.\n    let mainOutput: OutputNode;\n\n    for (const child of children) {\n      if (child instanceof OutputNode) {\n        let lastOutput = child;\n\n        while (lastOutput.numChildren() === 1) {\n          const [theChild] = lastOutput.children;\n          if (theChild instanceof OutputNode) {\n            lastOutput = theChild;\n          } else {\n            break;\n          }\n        }\n\n        otherChildren.push(...lastOutput.children);\n\n        if (mainOutput) {\n          // Move the output nodes before the mainOutput. We do this by setting\n          // the parent of the first not to the parent of the main output and\n          // the main output's parent to the last output.\n\n          // note: the child is the first output\n          node.removeChild(child);\n          child.parent = mainOutput.parent;\n\n          mainOutput.parent.removeChild(mainOutput);\n          mainOutput.parent = lastOutput;\n\n          this.setModified();\n        } else {\n          mainOutput = lastOutput;\n        }\n      } else {\n        otherChildren.push(child);\n      }\n    }\n\n    if (otherChildren.length) {\n      this.setModified();\n      for (const child of otherChildren) {\n        child.parent.removeChild(child);\n        child.parent = mainOutput;\n      }\n    }\n  }\n}\n"]},"metadata":{},"sourceType":"module"}